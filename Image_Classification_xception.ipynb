{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification using Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "N9MQiJl3yfDX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import PIL.Image as Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkyesplSyh4F"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xyyF1vzNyh7H"
   },
   "outputs": [],
   "source": [
    "folder1 = '/content/drive/MyDrive/race0'\n",
    "folder2 = '/content/drive/MyDrive/race1'\n",
    "folder3 = '/content/drive/MyDrive/race2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JrivUn2E3Owk"
   },
   "outputs": [],
   "source": [
    "def preprocess_input(x): \n",
    "   x = np.divide(x, 255.0) \n",
    "   x = np.subtract(x, 1.0) \n",
    "   x = np.multiply(x, 2.0) \n",
    "   return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "onao_Nt_yh-G"
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "gender = []\n",
    "race = []\n",
    "for filename in os.listdir(folder1):\n",
    "            img = Image.open(os.path.join(folder1, filename)).resize((150, 150))\n",
    "            img = np.array(img)\n",
    "            img = preprocess_input(img)\n",
    "            images.append(img)\n",
    "            gender.append(int(filename[3]))\n",
    "            race.append(int(filename[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dhiCas2wyiAR"
   },
   "outputs": [],
   "source": [
    "for filename in os.listdir(folder2):\n",
    "            img = Image.open(os.path.join(folder2, filename)).resize((150, 150))\n",
    "            img = np.array(img)\n",
    "            img = preprocess_input(img)\n",
    "            images.append(img)\n",
    "            gender.append(int(filename[3]))\n",
    "            race.append(int(filename[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8tC94ULiyiDW"
   },
   "outputs": [],
   "source": [
    "for filename in os.listdir(folder3):\n",
    "            img = Image.open(os.path.join(folder3, filename)).resize((150, 150))\n",
    "            img = np.array(img)\n",
    "            img = preprocess_input(img)\n",
    "            images.append(img)\n",
    "            gender.append(int(filename[3]))\n",
    "            race.append(int(filename[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cdqpbvWkyiGL"
   },
   "outputs": [],
   "source": [
    "images = np.asarray(images, dtype = 'float')\n",
    "gender = np.asarray(gender, dtype = 'int')\n",
    "race = np.asarray(race, dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TMu7DxMjyiJD"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    images,\n",
    "    gender,\n",
    "    test_size = 0.2,\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "VMSEFgdCyiLz"
   },
   "outputs": [],
   "source": [
    "base_model = keras.applications.xception.Xception(\n",
    "    weights = 'imagenet',\n",
    "    input_shape = (150, 150, 3),\n",
    "    include_top = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "-I454NN1yiOu"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "UPkSWa2FyiR9"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(\n",
    "    shape = (150, 150, 3)\n",
    ")\n",
    "x = base_model(inputs, training = False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "dMkG2EbqyiU_"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'BinaryCrossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ByV4PnRO13m8",
    "outputId": "1c23e42c-9e0f-4ebe-9c43-627208aeed03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "240/240 [==============================] - 24s 84ms/step - loss: 0.4195 - accuracy: 0.8058 - val_loss: 0.3681 - val_accuracy: 0.8458\n",
      "Epoch 2/8\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 0.3399 - accuracy: 0.8544 - val_loss: 0.3633 - val_accuracy: 0.8542\n",
      "Epoch 3/8\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 0.3137 - accuracy: 0.8653 - val_loss: 0.3750 - val_accuracy: 0.8521\n",
      "Epoch 4/8\n",
      "240/240 [==============================] - 19s 79ms/step - loss: 0.2955 - accuracy: 0.8763 - val_loss: 0.3548 - val_accuracy: 0.8542\n",
      "Epoch 5/8\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 0.2785 - accuracy: 0.8847 - val_loss: 0.3643 - val_accuracy: 0.8458\n",
      "Epoch 6/8\n",
      "240/240 [==============================] - 19s 81ms/step - loss: 0.2588 - accuracy: 0.8951 - val_loss: 0.3633 - val_accuracy: 0.8458\n",
      "Epoch 7/8\n",
      "240/240 [==============================] - 19s 80ms/step - loss: 0.2522 - accuracy: 0.8987 - val_loss: 0.3795 - val_accuracy: 0.8562\n",
      "Epoch 8/8\n",
      "240/240 [==============================] - 19s 80ms/step - loss: 0.2418 - accuracy: 0.9045 - val_loss: 0.3725 - val_accuracy: 0.8542\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs = 8,\n",
    "          batch_size = 8,\n",
    "          validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5eVayst13pF",
    "outputId": "86d81ce7-582e-4194-c392-8f2f63c67c5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 6s 189ms/step - loss: 0.3129 - accuracy: 0.8781\n",
      "0.8781301975250244\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "test_accuracy = score[1]\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtjd2MmE13ts"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "RpXAHqW9_ndo"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    images,\n",
    "    race,\n",
    "    test_size = 0.2,\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "leMXx6Aj_ngd"
   },
   "outputs": [],
   "source": [
    "base_model = keras.applications.xception.Xception(\n",
    "    weights = 'imagenet',\n",
    "    input_shape = (150, 150, 3),\n",
    "    include_top = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "lRlc4D4s_njZ"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "2RvnS-Hl_nmN"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(\n",
    "    shape = (150, 150, 3)\n",
    ")\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dense(1000, activation = 'relu')(x)\n",
    "x = keras.layers.Dropout(0.3)(x)\n",
    "x = keras.layers.Dense(250, activation = 'relu')(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "outputs = keras.layers.Dense(3, activation = 'softmax')(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "jvwdmHKI_noZ"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yOKljB7SAwth",
    "outputId": "d05fead9-7086-430f-fc2b-05b5667adc93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "255/255 [==============================] - 22s 73ms/step - loss: 1.0692 - accuracy: 0.4936 - val_loss: 0.8864 - val_accuracy: 0.5944\n",
      "Epoch 2/10\n",
      "255/255 [==============================] - 17s 67ms/step - loss: 0.8786 - accuracy: 0.6007 - val_loss: 0.8918 - val_accuracy: 0.5639\n",
      "Epoch 3/10\n",
      "255/255 [==============================] - 17s 67ms/step - loss: 0.8168 - accuracy: 0.6424 - val_loss: 0.8526 - val_accuracy: 0.6194\n",
      "Epoch 4/10\n",
      "255/255 [==============================] - 17s 67ms/step - loss: 0.7536 - accuracy: 0.6621 - val_loss: 0.8921 - val_accuracy: 0.6444\n",
      "Epoch 5/10\n",
      "255/255 [==============================] - 17s 67ms/step - loss: 0.6738 - accuracy: 0.7033 - val_loss: 0.8437 - val_accuracy: 0.6528\n",
      "Epoch 6/10\n",
      "255/255 [==============================] - 17s 67ms/step - loss: 0.6302 - accuracy: 0.7195 - val_loss: 0.8525 - val_accuracy: 0.6389\n",
      "Epoch 7/10\n",
      "255/255 [==============================] - 17s 68ms/step - loss: 0.5609 - accuracy: 0.7662 - val_loss: 1.0221 - val_accuracy: 0.6083\n",
      "Epoch 8/10\n",
      "255/255 [==============================] - 17s 66ms/step - loss: 0.5142 - accuracy: 0.7790 - val_loss: 1.0125 - val_accuracy: 0.6389\n",
      "Epoch 9/10\n",
      "255/255 [==============================] - 17s 67ms/step - loss: 0.4275 - accuracy: 0.8168 - val_loss: 1.0534 - val_accuracy: 0.6111\n",
      "Epoch 10/10\n",
      "255/255 [==============================] - 17s 68ms/step - loss: 0.4378 - accuracy: 0.8193 - val_loss: 1.0409 - val_accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs = 10,\n",
    "          batch_size = 8,\n",
    "          validation_split = 0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DGQJnlfAxov",
    "outputId": "e421fd63-de6d-41fb-ed8d-a4a37ca2a88a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 4s 142ms/step - loss: 0.9935 - accuracy: 0.6528\n",
      "0.6527546048164368\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "test_accuracy = score[1]\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Image_Classification_xception.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
